{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob\n",
    "\n",
    "TextBlob is a Python (2 and 3) library for processing textual data.  \n",
    "It provides a simple API for diving into common Natural Language Processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a python library and offers a simple API to access its methods and perform basic NLP tasks. \n",
    "\n",
    "<hr>\n",
    "\n",
    "A good thing about TextBlob is that they are just like python strings. So, you can transform and play with it same like we did in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"naly\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = TextBlob(\"Analytics\")\n",
    "\n",
    "string1[1:5] # Extracting 1 to 5 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"ANALYTICS\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.upper() # Convert text to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2 = TextBlob(\"Vidhya\")\n",
    "\n",
    "# concat\n",
    "string1 + \" \" + string2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Tokenization refers to dividing text or a sentence into a sequence of tokens, which roughly correspond to “words”.  \n",
    "This is one of the basic tasks of NLP.  \n",
    "\n",
    "To do this using TextBlob, follow the two steps:\n",
    "1. Create a **textblob** object and pass a string with it.\n",
    "2. Call **functions** of textblob in order to do a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Analytics Vidhya is a great platform to learn data science.\"),\n",
       " Sentence(\"It helps community through blogs, hackathons, discussions,etc.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing Sentences\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"Analytics Vidhya is a great platform to learn data science.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting only the first sentence\n",
    "blob.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics\n",
      "Vidhya\n",
      "is\n",
      "a\n",
      "great\n",
      "platform\n",
      "to\n",
      "learn\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "# Printing words of first sentence\n",
    "for words in blob.sentences[0].words:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Analytics', 'Vidhya', 'is', 'a', 'great', 'platform', 'to', 'learn', 'data', 'science', 'It', 'helps', 'community', 'through', 'blogs', 'hackathons', 'discussions', 'etc'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all words\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Phrase Extraction\n",
    "\n",
    "Since we extracted the words in the previous section, instead of that we can just extract out the noun phrases from the textblob.  \n",
    "Noun Phrase extraction is particularly important when you want to analyze the “who” in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics vidhya\n",
      "great platform\n",
      "data science\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science.\")\n",
    "\n",
    "for np in blob.noun_phrases:\n",
    "    print (np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech Tagging\n",
    "\n",
    "Part-of-speech tagging or grammatical tagging is a method to mark words present in a text on the basis of its definition and context.  \n",
    "In simple words, it tells whether a word is a noun, or an adjective, or a verb, etc.  \n",
    "This is just a complete version of noun phrase extraction, where we want to find all the the parts of speech in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics NNS\n",
      "Vidhya NNP\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "platform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print(words, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inflection* is a process of word formation in which characters are added to the base form of a word to express grammatical meanings.  \n",
    "Word inflection in TextBlob is very simple, i.e., the words we tokenized from a textblob can be easily changed into singular or plural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helps\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")\n",
    "\n",
    "print(blob.sentences[1].words[1])\n",
    "print(blob.sentences[1].words[1].singularize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob library also offers an in-build object known as *Word*.  \n",
    "We just need to create a word object and then apply a function directly to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word(\"Platform\")\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the tags to inflect a particular type of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "sciences\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "## Using Tags\n",
    "for word, pos in blob.tags:\n",
    "    if pos == 'NN':\n",
    "        print(word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words can be lemmatized using the *lemmatize* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatization\n",
    "w = Word(\"running\")\n",
    "\n",
    "w.lemmatize(\"v\") #Here 'v' represents verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "\n",
    "A combination of multiple words together are called N-Grams.  \n",
    "N grams (N > 1) are generally more informative as compared to words, and can be used as features for language modelling.  \n",
    "N-grams can be easily accessed in TextBlob using the **ngrams** function, which returns a tuple of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analytics', 'Vidhya']\n",
      "['Vidhya', 'is']\n",
      "['is', 'a']\n",
      "['a', 'great']\n",
      "['great', 'platform']\n",
      "['platform', 'to']\n",
      "['to', 'learn']\n",
      "['learn', 'data']\n",
      "['data', 'science']\n",
      "['science', 'It']\n",
      "['It', 'helps']\n",
      "['helps', 'community']\n",
      "['community', 'through']\n",
      "['through', 'blogs']\n",
      "['blogs', 'hackathons']\n",
      "['hackathons', 'discussions']\n",
      "['discussions', 'etc']\n"
     ]
    }
   ],
   "source": [
    "for ngram in blob.ngrams(2):\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is basically the process of determining the attitude or the emotion of the writer, i.e., whether it is positive or negative or neutral.\n",
    "\n",
    "The sentiment function of textblob returns two properties, **polarity**, and **subjectivity**.\n",
    "\n",
    "Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement.  \n",
    "Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information.  \n",
    "Subjectivity is also a float which lies in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics Vidhya is a great platform to learn data science. \n",
      " It helps community through blogs, hackathons, discussions,etc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(blob)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that polarity is **0.8**, which means that the statement is positive and **0.75** subjectivity refers that mostly it is a public opinion and not a factual information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "\n",
    "Spelling correction is a cool feature which TextBlob offers, we can be accessed using the **correct** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya is a great platform to learn data science\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('Analytics Vidhya is a gret platfrm to learn data scence')\n",
    "\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the list of suggested word and its confidence using the **spellcheck** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.5351351351351351),\n",
       " ('get', 0.3162162162162162),\n",
       " ('grew', 0.11216216216216217),\n",
       " ('grey', 0.026351351351351353),\n",
       " ('greet', 0.006081081081081081),\n",
       " ('fret', 0.002702702702702703),\n",
       " ('grit', 0.0006756756756756757),\n",
       " ('cret', 0.0006756756756756757)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[4].spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a short summary of a text\n",
    "\n",
    "This is a simple trick in which we will be using the things we learned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "blob = TextBlob('Analytics Vidhya is a thriving community for data driven industry. This platform allows \\\n",
    "people to know more about analytics from its articles, Q&A forum, and learning paths. Also, we help \\\n",
    "professionals & amateurs to sharpen their skillsets by providing a platform to participate in Hackathons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about...\n",
      "forums\n",
      "communities\n",
      "industries\n",
      "platforms\n",
      "platforms\n"
     ]
    }
   ],
   "source": [
    "nouns = list()\n",
    "\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())      \n",
    "       \n",
    "print('This text is about...')\n",
    "\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "    print(word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did above that we extracted out a list of nouns from the text to give a general idea to the reader about the things the text is related to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation and Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('هذا بارد') # Arabic Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it is Arabic. Now, let’s find translate it into English so that we can know what is written using TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"that's cool\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translate to English\n",
    "blob.translate(from_lang='ar', to='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you don’t explicitly define the source language, TextBlob will automatically detect the language and translate into the desired language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"that's cool\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(to='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "Let’s build a simple text classification model using TextBlob. For this, first, we need to prepare a training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textblob provides in-build classifiers module to create a custom classifier. So, let’s quickly import it and create a basic classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "nb_classifier = classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we have passed the training data into the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we have used Naive Bayes classifier, but TextBlob also offers Decision tree classifier which is as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "dt_classifier = classifiers.DecisionTreeClassifier(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s check the accuracy of this classifier on the testing dataset and also TextBlob provides us to check the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n",
      "             contains(a) = False             neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(nb_classifier.accuracy(testing))\n",
    "nb_classifier.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, we can see that if the text contains “is”, then there is a high probability that the statement will be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to give a little more idea, let’s check our classifier on a random text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('The weather is terrible!', classifier=nb_classifier)\n",
    "\n",
    "print(blob.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, based on the training on the above dataset, our classifier has provided us the right result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons:\n",
    "\n",
    "### Pros:\n",
    "1. Since, it is built on the shoulders of NLTK and Pattern, therefore making it simple for beginners by providing an intuitive interface to NLTK.\n",
    "2. It provides language translation and detection which is powered by Google Translate (not provided with spaCy)\n",
    "\n",
    "### Cons:\n",
    "1. It is little slower in the comparison to spaCy but faster than NLTK. (spaCy > TextBlob > NLTK)\n",
    "2. It does not provide features like dependency parsing, word vectors etc. which is provided by spacy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
